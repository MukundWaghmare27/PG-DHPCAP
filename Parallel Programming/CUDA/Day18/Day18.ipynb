{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Matrix Multiplication On CPU & GPU"
      ],
      "metadata": {
        "id": "puR5Cq4SaKjM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uz0PMgzjzygY",
        "outputId": "4ceb3752-b38e-4bea-9c05-e1c7b9f8c259"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 1.cpp\n"
          ]
        }
      ],
      "source": [
        "%%writefile 1.cpp\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "\n",
        "#define N 2\n",
        "\n",
        "void matrix_multiplication(int a[N][N], int b[N][N], int c[N][N]){\n",
        "  for(int i=0; i<N; i++){\n",
        "    for(int j=0; j<N; j++){\n",
        "      c[i][j]=0;\n",
        "      for(int k=0; k<N; k++){\n",
        "        c[i][j] += a[i][k] * b[k][j];\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  int a[N][N] = {{1,7}, {2,4}};\n",
        "  int b[N][N] = {{3,3}, {5,2}};\n",
        "  int c[N][N];\n",
        "\n",
        "  matrix_multiplication(a,b,c);\n",
        "\n",
        "  printf(\"Resultant Matrix: \\n\");\n",
        "  for(int i=0; i<N; i++){\n",
        "    for(int j=0; j<N; j++){\n",
        "      printf(\"%d \", c[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  return 0;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!g++ -o 1 1.cpp"
      ],
      "metadata": {
        "id": "EcIV2ZNW1sj0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN1Ou1FT1vbN",
        "outputId": "8fc7e11c-532a-45a7-a139-d3b37aac2747"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultant Matrix: \n",
            "38 17 \n",
            "26 14 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "//Own written code\n",
        "%%writefile 2.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <chrono>\n",
        "#include <time.h>\n",
        "\n",
        "#define N 2\n",
        "\n",
        "__global__ void matrix_multiply_gpu(int a[N][N], int *b[N][N], int *c[N][N]){\n",
        "  int id = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "  if(id < N * N){\n",
        "    for(int i=0; i<N; i++){\n",
        "      for(int j=0; j<N; j++){\n",
        "        c[i][j]=0;\n",
        "        for(int k=0; k<N; k++){\n",
        "          c[i][j] += a[i][k] * b[k][j];\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "  }\n",
        "}\n",
        "\n",
        "void matrix_multiplication(int a[N][N], int b[N][N], int c[N][N]){\n",
        "  for(int i=0; i<N; i++){\n",
        "    for(int j=0; j<N; j++){\n",
        "      c[i][j]=0;\n",
        "      for(int k=0; k<N; k++){\n",
        "        c[i][j] += a[i][k] * b[k][j];\n",
        "      }\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "int main(){\n",
        "  int a[N][N] = {{1,7}, {2,4}};\n",
        "  int b[N][N] = {{3,3}, {5,2}};\n",
        "  int c[N][N];\n",
        "\n",
        "  matrix_multiplication(a,b,c);\n",
        "\n",
        "  printf(\"Resultant Matrix: \\n\");\n",
        "  for(int i=0; i<N; i++){\n",
        "    for(int j=0; j<N; j++){\n",
        "      printf(\"%d \", c[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  int *d_a, *d_b, *d_c;\n",
        "  int h_c[N][N];\n",
        "\n",
        "  cudaMalloc((void**)&d_a, N*N *sizeof(int));\n",
        "  cudaMalloc((void**)&d_b, N*N * sizeof(int));\n",
        "  cudaMalloc((void**)&d_c, N*N * sizeof(int));\n",
        "\n",
        "  cudaMemcpy(d_a, a, N*N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "  cudaMemcpy(d_b, b, N*N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "  matrix_multiply_gpu<<<1, 4>>>(d_a, d_b, d_c);\n",
        "\n",
        "  cudaMemcpy(c, d_c, N*N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "  printf(\"Resulatant Matrix from GPU: \\n\");\n",
        "  for(int i; i<N, i++){\n",
        "    for(int j=0; j<N; j++){\n",
        "      printf(\"%d \", h_c[i][j]);\n",
        "    }\n",
        "    printf(\"\\n\");\n",
        "  }\n",
        "\n",
        "  cudaFree(d_a);\n",
        "  cudafree(d_b);\n",
        "  cudafree(d_c);\n",
        "\n",
        "  return 0;\n",
        "}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waI3Whza182l",
        "outputId": "1aba6614-5885-40d2-ca2f-c4db91f560d2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 2.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o 2 2.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xb5pr0hn6yND",
        "outputId": "4df8aacd-c78a-4bfe-bcc6-f7e91ef92feb"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m2.cu(18)\u001b[0m: \u001b[01;31merror\u001b[0m: expression must have arithmetic or unscoped enum type\n",
            "            c[i][j] += a[i][k] * b[k][j];\n",
            "                                 ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m2.cu(61)\u001b[0m: \u001b[01;31merror\u001b[0m: argument of type \"int *\" is incompatible with parameter of type \"int (*)[2]\"\n",
            "    matrix_multiply_gpu<<<1, 4>>>(d_a, d_b, d_c);\n",
            "                                  ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m2.cu(61)\u001b[0m: \u001b[01;31merror\u001b[0m: argument of type \"int *\" is incompatible with parameter of type \"int *(*)[2]\"\n",
            "    matrix_multiply_gpu<<<1, 4>>>(d_a, d_b, d_c);\n",
            "                                       ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m2.cu(61)\u001b[0m: \u001b[01;31merror\u001b[0m: argument of type \"int *\" is incompatible with parameter of type \"int *(*)[2]\"\n",
            "    matrix_multiply_gpu<<<1, 4>>>(d_a, d_b, d_c);\n",
            "                                            ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m2.cu(66)\u001b[0m: \u001b[01;35mwarning\u001b[0m #549-D: variable \u001b[01m\"i\"\u001b[0m is used before its value is set\n",
            "    for(int i; i<2, i++){\n",
            "               ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m2.cu(66)\u001b[0m: \u001b[01;35mwarning\u001b[0m #174-D: expression has no effect\n",
            "    for(int i; i<2, i++){\n",
            "               ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m2.cu(66)\u001b[0m: \u001b[01;31merror\u001b[0m: expected a \";\"\n",
            "    for(int i; i<2, i++){\n",
            "                       ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m2.cu(74)\u001b[0m: \u001b[01;31merror\u001b[0m: identifier \"\u001b[01mcudafree\u001b[0m\" is undefined\n",
            "    cudafree(d_b);\n",
            "    ^\n",
            "\n",
            "6 errors detected in the compilation of \"2.cu\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "//corrected using AI bot\n",
        "%%writefile 3.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <chrono>\n",
        "#include <time.h>\n",
        "\n",
        "#define N 2\n",
        "\n",
        "__global__ void matrix_multiply_gpu(int *a, int *b, int *c) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        int value = 0;\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            value += a[row * N + k] * b[k * N + col];\n",
        "        }\n",
        "        c[row * N + col] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "void matrix_multiplication(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            c[i][j] = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                c[i][j] += a[i][k] * b[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a[N][N] = {{1, 7}, {2, 4}};\n",
        "    int b[N][N] = {{3, 3}, {5, 2}};\n",
        "    int c[N][N] = {0};\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    matrix_multiplication(a, b, c);\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    double elapsed_time_cpu = std::chrono::duration<double, std::milli>(end - start).count();\n",
        "\n",
        "    printf(\"Resultant Matrix (CPU): \\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"CPU Execution Time: %.3f ms\\n\", elapsed_time_cpu);\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    int h_c[N][N] = {0};\n",
        "\n",
        "    cudaMalloc((void**)&d_a, N * N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_b, N * N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_c, N * N * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(2, 2);\n",
        "    dim3 blocksPerGrid(1, 1);\n",
        "\n",
        "    cudaEvent_t start_event, stop_event;\n",
        "    cudaEventCreate(&start_event);\n",
        "    cudaEventCreate(&stop_event);\n",
        "\n",
        "    cudaEventRecord(start_event, 0);\n",
        "    matrix_multiply_gpu<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c);\n",
        "    cudaEventRecord(stop_event, 0);\n",
        "    cudaEventSynchronize(stop_event);\n",
        "\n",
        "    float elapsed_time_gpu = 0;\n",
        "    cudaEventElapsedTime(&elapsed_time_gpu, start_event, stop_event);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"\\nResultant Matrix (GPU): \\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", h_c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "     printf(\"GPU Execution Time: %.3f ms\\n\", elapsed_time_gpu);\n",
        "\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ygAdT3QV607-",
        "outputId": "32c9e596-b991-4096-f012-c5c6792626b5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 3.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o 3 3.cu"
      ],
      "metadata": {
        "id": "q4QtLv0f835K"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4pz1vog89kO",
        "outputId": "334dbbae-d59e-44d8-b258-8a339ba85cce"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Resultant Matrix (CPU): \n",
            "38 17 \n",
            "26 14 \n",
            "CPU Execution Time: 0.000 ms\n",
            "\n",
            "Resultant Matrix (GPU): \n",
            "38 17 \n",
            "26 14 \n",
            "GPU Execution Time: 0.165 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile 4.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <chrono>\n",
        "#include <time.h>\n",
        "\n",
        "#define N 2\n",
        "\n",
        "__global__ void matrix_multiply_gpu(int *a, int *b, int *c) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        int value = 0;\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            value += a[row * N + k] * b[k * N + col];\n",
        "        }\n",
        "        c[row * N + col] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "void matrix_multiplication(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            c[i][j] = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                c[i][j] += a[i][k] * b[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a[N][N] = {0};\n",
        "    int b[N][N] = {0};\n",
        "    int c[N][N] = {0};\n",
        "\n",
        "    for(int i=0; i<N; i++){\n",
        "      for(int j=0; i<N; j++){\n",
        "        a[i][j];\n",
        "        b[i][j];\n",
        "      }\n",
        "    }\n",
        "\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    matrix_multiplication(a, b, c);\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    double elapsed_time_cpu = std::chrono::duration<double, std::milli>(end - start).count();\n",
        "\n",
        "    printf(\"Resultant Matrix (CPU): \\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"CPU Execution Time: %.3f ms\\n\", elapsed_time_cpu);\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    int h_c[N][N] = {0};\n",
        "\n",
        "    cudaMalloc((void**)&d_a, N * N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_b, N * N * sizeof(int));\n",
        "    cudaMalloc((void**)&d_c, N * N * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    dim3 threadsPerBlock(2, 2);\n",
        "    dim3 blocksPerGrid(1, 1);\n",
        "\n",
        "    cudaEvent_t start_event, stop_event;\n",
        "    cudaEventCreate(&start_event);\n",
        "    cudaEventCreate(&stop_event);\n",
        "\n",
        "    cudaEventRecord(start_event, 0);\n",
        "    matrix_multiply_gpu<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c);\n",
        "    cudaEventRecord(stop_event, 0);\n",
        "    cudaEventSynchronize(stop_event);\n",
        "\n",
        "    float elapsed_time_gpu = 0;\n",
        "    cudaEventElapsedTime(&elapsed_time_gpu, start_event, stop_event);\n",
        "\n",
        "    cudaMemcpy(h_c, d_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"\\nResultant Matrix (GPU): \\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", h_c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "     printf(\"GPU Execution Time: %.3f ms\\n\", elapsed_time_gpu);\n",
        "\n",
        "\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5q-xKkuU8-v2",
        "outputId": "61a38504-69e6-4806-f125-203fc9d1072f"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing 4.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o 4 4.cu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMUTDv1EAVbA",
        "outputId": "b15a7c49-5206-4310-ee9b-37f947f5edb5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01m\u001b[0m\u001b[01m4.cu(41)\u001b[0m: \u001b[01;35mwarning\u001b[0m #174-D: expression has no effect\n",
            "          a[i][j];\n",
            "          ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m4.cu(42)\u001b[0m: \u001b[01;35mwarning\u001b[0m #174-D: expression has no effect\n",
            "          b[i][j];\n",
            "          ^\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m4.cu(41)\u001b[0m: \u001b[01;35mwarning\u001b[0m #174-D: expression has no effect\n",
            "          a[i][j];\n",
            "          ^\n",
            "\n",
            "\u001b[01;36m\u001b[0m\u001b[01;36mRemark\u001b[0m: The warnings can be suppressed with \"-diag-suppress <warning-number>\"\n",
            "\n",
            "\u001b[01m\u001b[0m\u001b[01m4.cu(42)\u001b[0m: \u001b[01;35mwarning\u001b[0m #174-D: expression has no effect\n",
            "          b[i][j];\n",
            "          ^\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "//Tried To increase matrix size\n",
        "\n",
        "%%writefile 5.cu\n",
        "\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda.h>\n",
        "#include <chrono>\n",
        "\n",
        "#define N 10\n",
        "\n",
        "// Kernel for matrix multiplication on the GPU\n",
        "__global__ void matrix_multiply_gpu(int *a, int *b, int *c) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "\n",
        "    if (row < N && col < N) {\n",
        "        int value = 0;\n",
        "        for (int k = 0; k < N; k++) {\n",
        "            value += a[row * N + k] * b[k * N + col];\n",
        "        }\n",
        "        c[row * N + col] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "// Function for matrix multiplication on the CPU\n",
        "void matrix_multiplication(int a[N][N], int b[N][N], int c[N][N]) {\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            c[i][j] = 0;\n",
        "            for (int k = 0; k < N; k++) {\n",
        "                c[i][j] += a[i][k] * b[k][j];\n",
        "            }\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int a[N][N] = {0};\n",
        "    int b[N][N] = {0};\n",
        "    int c[N][N] = {0};\n",
        "\n",
        "    printf(\"Initializing matrices...\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            a[i][j] = rand() % 10;\n",
        "            b[i][j] = rand() % 10;\n",
        "        }\n",
        "    }\n",
        "\n",
        "    // Perform matrix multiplication on CPU\n",
        "    auto start = std::chrono::high_resolution_clock::now();\n",
        "    matrix_multiplication(a, b, c);\n",
        "    auto end = std::chrono::high_resolution_clock::now();\n",
        "\n",
        "    double elapsed_time_cpu = std::chrono::duration<double, std::milli>(end - start).count();\n",
        "\n",
        "    printf(\"Resultant Matrix (CPU):\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"CPU Execution Time: %.3f ms\\n\", elapsed_time_cpu);\n",
        "\n",
        "    int *d_a, *d_b, *d_c;\n",
        "    int h_c[N][N] = {0};\n",
        "\n",
        "    cudaMalloc((void **)&d_a, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&d_b, N * N * sizeof(int));\n",
        "    cudaMalloc((void **)&d_c, N * N * sizeof(int));\n",
        "\n",
        "    cudaMemcpy(d_a, a, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(d_b, b, N * N * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    int threadsPerBlock = 256;\n",
        "    int blocksPerGrid = (N + threadsPerBlock - 1) / threadsPerBlock;\n",
        "\n",
        "    // GPU timing events\n",
        "    cudaEvent_t start_event, stop_event;\n",
        "    cudaEventCreate(&start_event);\n",
        "    cudaEventCreate(&stop_event);\n",
        "\n",
        "    cudaEventRecord(start_event, 0);\n",
        "    matrix_multiply_gpu<<<blocksPerGrid, threadsPerBlock>>>(d_a, d_b, d_c);\n",
        "    cudaEventRecord(stop_event, 0);\n",
        "    cudaEventSynchronize(stop_event);\n",
        "\n",
        "    float elapsed_time_gpu = 0;\n",
        "    cudaEventElapsedTime(&elapsed_time_gpu, start_event, stop_event);\n",
        "\n",
        "    // Copy result back to host\n",
        "    cudaMemcpy(h_c, d_c, N * N * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    printf(\"\\nResultant Matrix (GPU):\\n\");\n",
        "    for (int i = 0; i < N; i++) {\n",
        "        for (int j = 0; j < N; j++) {\n",
        "            printf(\"%d \", h_c[i][j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    printf(\"GPU Execution Time: %.3f ms\\n\", elapsed_time_gpu);\n",
        "\n",
        "    // Free GPU memory\n",
        "    cudaFree(d_a);\n",
        "    cudaFree(d_b);\n",
        "    cudaFree(d_c);\n",
        "\n",
        "    return 0;\n",
        "}\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUvC8_0UAiAm",
        "outputId": "cbf0945a-e14f-4de7-e235-55343ba6a19c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting 5.cu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvcc -o 5 5.cu"
      ],
      "metadata": {
        "id": "zHQOiP4PBdlo"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!./5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGvN-XDBBqS_",
        "outputId": "05a6a476-b8be-4b0b-d36a-e0afc6aac5cf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initializing matrices...\n",
            "Resultant Matrix (CPU):\n",
            "190 278 145 132 190 136 200 169 161 167 \n",
            "186 355 156 157 207 209 185 164 210 246 \n",
            "191 335 233 179 196 257 220 227 174 232 \n",
            "191 319 172 156 167 218 182 186 165 186 \n",
            "276 433 239 205 229 305 251 252 193 257 \n",
            "233 378 222 181 218 240 231 216 180 226 \n",
            "232 430 221 155 255 274 187 203 193 328 \n",
            "248 319 178 137 201 217 233 171 165 236 \n",
            "267 379 184 141 231 276 259 247 218 301 \n",
            "252 477 239 204 282 302 239 261 245 334 \n",
            "CPU Execution Time: 0.007 ms\n",
            "\n",
            "Resultant Matrix (GPU):\n",
            "190 278 145 132 190 136 200 169 161 167 \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "GPU Execution Time: 38.644 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EUhHE3zfBsXv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}